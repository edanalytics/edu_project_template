# Nulls are represented in two different ways across this YAML:
# - `null`: An empty value
# - `~`   : A placeholder that must be populated in each specific DAG-implementation.

default_task_args: &default_task_args
  owner: 'airflow'
  run_as_user: null
  depends_on_past: False
  start_date: '2020-05-17'
  email:
    - 'EMAIL@edanalytics.org'
  email_on_failure: False
  retries: 0
  trigger_rule: 'all_success'
  retry_delay: !timedelta 300  # 5 minutes
  execution_timeout: !timedelta 21600  # 6 hours
  sla: !timedelta 86400  # 24 hours


variables:
  dbt_incrementer_var: &dbt_incrementer_var 'COMPLETED_EDFI_DAG_RUNS'


### AWS Parameter Store to Airflow connections DAG
aws_param_store_dag:
  schedule_interval: null
  default_args: *default_task_args

  region_name: 'us-east-2'
  connection_mapping: ~

  prefix_year_mapping: ~
  tenant_mapping: ~




### Ed-Fi Resource/Descriptor DAGs
edfi_resource_dags__default_args: &edfi_resource_dags__default_args
  default_args: *default_task_args

  schedule_interval: '0 */8 * * *'
  schedule_interval_resources: ~    # Optional to provide differing schedule logic between resources and descriptors.
  schedule_interval_descriptors: ~  # If either is unpopulated, `schedule_interval` will be used by default.

  # Airflow Connection IDs
  edfi_conn_id: ~
  s3_conn_id: 'data_lake'
  snowflake_conn_id: 'snowflake'
  slack_conn_id: 'slack'
  adls_conn_id: 'ADLS'
  databricks_conn_id: 'databricks'
  adls_storage_account: 'tedsdevdata'
  adls_container: 'ed-fi'
  # Airflow Variables
  dbt_incrementer_var: *dbt_incrementer_var

  # Variables for pulling from EdFi
  tmp_dir: '/opt/airflow/tmp_data'
  pool: ~

  # Variables for interacting with Snowflake
  change_version_table: '_meta_change_versions'


edfi_resource_dags:
  TDOE:
    2026:
      pool: default_pool
      edfi_conn_id: 'edfi_TENANT1_YEAR2026'
      schedule_interval: null
      <<: *edfi_resource_dags__default_args
    2025:
      pool: default_pool
      edfi_conn_id: 'edfi_TENANT1_YEAR2025'
      schedule_interval: null
      <<: *edfi_resource_dags__default_args
    2024:
      pool: default_pool
      edfi_conn_id: 'edfi_TENANT1_YEAR2024'
      schedule_interval: null
      <<: *edfi_resource_dags__default_args


### DBT Run DAG
dbt_run_dags__default_args: &dbt_run_dags__default_args
  schedule_interval: null
  default_args: *default_task_args

  dbt_bin_path: '/home/airflow/.venv/dbt/bin/dbt'
  dbt_repo_path: ~

  full_refresh: False
  full_refresh_schedule: null

  opt_dest_schema: ~
  opt_swap: False

  upload_artifacts: True

  slack_conn_id: 'slack'

  # Airflow Variables
  dbt_incrementer_var: *dbt_incrementer_var


dbt_run_dags:
  rc:
    dbt_repo_path: '/home/airflow/code/PROJECT_REPO/dbt'
    dbt_target_name: 'rc'
    <<: *dbt_run_dags__default_args
  prod:
    dbt_repo_path: '/home/airflow/code/PROJECT_REPO/dbt'
    dbt_target_name: 'prod'
    <<: *dbt_run_dags__default_args




### dbt docs update DAG
dbt_docs_update:
  dbt_bin_path: '/home/airflow/.venv/dbt/bin/dbt'
  dbt_target_name: 'prod'
  dbt_repo_path: '/home/airflow/code/PROJECT_REPO/dbt'
  dbt_docs_s3_conn_id: dbt_docs_s3
  schedule_interval: '@weekly'
  default_args: *default_task_args




## Airflow DB Clean DAG
airflow_db_clean:
  retention_days: 90
  dry_run: False
  verbose: True
  dag_id: "airflow_db_clean"
  schedule_interval: '@weekly'
  default_args: *default_task_args
